# API Testing Guide

This directory contains comprehensive testing tools and documentation for the Agentic RAG API.

## ğŸ“ Contents

### Test Files (`test_files/`)
- `sample_document.txt` - General information about the RAG system
- `ai_guide.md` - AI and machine learning concepts  
- `python_guide.txt` - Python programming guide

### Testing Scripts
- `test_api.py` - Comprehensive automated API testing
- `manual_test.py` - Interactive manual testing script

### Test Collections
- `Agentic_RAG_API.postman_collection.json` - Postman collection for API testing

## ğŸš€ Quick Start

### 1. Start the API Server
```bash
cd /Users/ditthapong/Desktop/cofive-agentic-RAG
python3 api_server.py
```

### 2. Run Automated Tests
```bash
cd tests
python3 test_api.py --save
```

### 3. Run Manual Tests
```bash
cd tests
python3 manual_test.py
```

## ğŸ“‹ Test Coverage

### Endpoints Tested
- âœ… `GET /health` - Health check
- âœ… `GET /status` - System status  
- âœ… `GET /models` - Available models
- âœ… `POST /upload` - Document upload
- âœ… `POST /initialize` - Agent initialization
- âœ… `POST /query` - Document querying
- âœ… `POST /reset` - System reset

### Test Scenarios
- âœ… Success cases
- âœ… Error handling
- âœ… Validation errors
- âœ… Invalid endpoints
- âœ… File upload (various formats)
- âœ… Model configuration
- âœ… Temperature validation

## ğŸ§ª Test Types

### Automated Testing (`test_api.py`)

**Features:**
- Complete endpoint coverage
- Error case testing
- Response validation
- Performance timing
- JSON result export
- Detailed logging

**Usage:**
```bash
# Basic testing
python3 test_api.py

# Save results to JSON
python3 test_api.py --save

# Custom API URL
python3 test_api.py --url http://localhost:8003

# Custom output file
python3 test_api.py --save --output my_results.json
```

**Output:**
```
ğŸš€ Starting Agentic RAG API Tests
==================================================

ğŸ“¡ Testing Basic Connectivity
âœ… PASS Health Check
âœ… PASS System Status
âœ… PASS Available Models

ğŸ“ Testing Document Upload
âœ… PASS Upload - No Files
âœ… PASS Upload - Valid Files
âœ… PASS Upload - Invalid File Type

ğŸ¤– Testing Agent Initialization
âœ… PASS Initialize - No Documents
âœ… PASS Initialize - Normal
âœ… PASS Initialize - Different Model

ğŸ’¬ Testing Query Processing
âœ… PASS Query - 'What is the Agentic RAG system?...'
âœ… PASS Query - 'What file formats are supported?...'

ğŸ“Š TEST SUMMARY
Total Tests: 25
Passed: 25
Failed: 0
Success Rate: 100.0%
Total Time: 45.23s
```

### Manual Testing (`manual_test.py`)

**Features:**
- Interactive testing
- Step-by-step guidance
- Human verification
- Educational walkthrough

**Usage:**
```bash
python3 manual_test.py
```

### Postman Collection

**Features:**
- Visual testing interface
- Pre-built requests
- Automated test assertions
- Environment variables
- Collection runner support

**Usage:**
1. Import `Agentic_RAG_API.postman_collection.json` into Postman
2. Set environment variable `base_url` to `http://localhost:8003`
3. Run collection or individual requests

## ğŸ“Š Test Results

### Sample Test Report
```json
{
  "test": "Health Check",
  "success": true,
  "details": "Status: healthy",
  "timestamp": "2025-09-14 17:00:00",
  "response_data": {
    "status": "healthy",
    "timestamp": "2025-09-14T17:00:00.000000",
    "version": "1.0.0"
  }
}
```

## ğŸ”§ Configuration

### Environment Variables
- `OPENAI_API_KEY` - Required for API functionality

### Test Configuration
- **Base URL**: `http://localhost:8003`
- **Timeout**: 30s for uploads, 60s for queries
- **Test Files**: Located in `test_files/` directory

## ğŸ“ Adding New Tests

### Automated Tests
Add new test methods to `AgenticRAGAPITester` class:

```python
def test_new_endpoint(self):
    """Test new endpoint"""
    try:
        response = self.session.get(f"{self.base_url}/new-endpoint")
        if response.status_code == 200:
            self.log_test("New Endpoint", True, "Success")
        else:
            self.log_test("New Endpoint", False, f"HTTP {response.status_code}")
    except Exception as e:
        self.log_test("New Endpoint", False, f"Exception: {str(e)}")
```

### Postman Tests
Add new requests to the collection with test scripts:

```javascript
pm.test("Status code is 200", function () {
    pm.response.to.have.status(200);
});

pm.test("Response has required field", function () {
    var jsonData = pm.response.json();
    pm.expect(jsonData).to.have.property('field_name');
});
```

## ğŸ› Troubleshooting

### Common Issues

1. **Connection Refused**
   ```
   Error: Connection refused
   ```
   **Solution**: Ensure API server is running on port 8003

2. **OpenAI API Key Missing**
   ```
   Error: OPENAI_API_KEY not found
   ```
   **Solution**: Set environment variable
   ```bash
   export OPENAI_API_KEY="your_key_here"
   ```

3. **File Upload Fails**
   ```
   Error: No files processed
   ```
   **Solution**: Check file paths and formats (PDF, TXT, MD only)

4. **Agent Not Ready**
   ```
   Error: Agent not ready
   ```
   **Solution**: Upload documents first, then initialize

### Debug Mode

Enable verbose logging for troubleshooting:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“ˆ Performance Benchmarks

### Expected Response Times
- Health check: < 100ms
- Status check: < 200ms
- Document upload: 1-10s (depending on size)
- Agent initialization: 2-5s
- Query processing: 1-5s

### Load Testing
For load testing, use tools like:
- Apache Bench (ab)
- wrk
- Postman Collection Runner

## ğŸ” Validation

### Response Validation
All tests validate:
- HTTP status codes
- Response structure
- Required fields
- Data types
- Business logic

### Error Handling
Tests cover:
- Invalid inputs
- Missing parameters
- Server errors
- Network issues
- Timeout scenarios

## ğŸ“š Documentation

- **API Documentation**: `/API_DOCUMENTATION.md`
- **OpenAPI/Swagger**: `http://localhost:8003/docs`
- **ReDoc**: `http://localhost:8003/redoc`

## ğŸ¯ Test Strategy

### Test Pyramid
1. **Unit Tests**: Individual component testing
2. **Integration Tests**: API endpoint testing (this directory)
3. **E2E Tests**: Full workflow testing
4. **Performance Tests**: Load and stress testing

### Testing Philosophy
- Test early and often
- Cover happy paths and edge cases
- Validate both success and failure scenarios
- Maintain test documentation
- Automate where possible

---

**Last Updated**: September 14, 2025  
**Version**: 1.0.0